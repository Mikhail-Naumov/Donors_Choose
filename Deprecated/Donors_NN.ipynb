{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Predicting Donors Choose</center>\n",
    "\n",
    "--------\n",
    "\n",
    "# Introduction\n",
    "*This notebook will use features designed more for NN:*\n",
    "- one hot encoding\n",
    "- seperate enviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#I would rather not run the while dataset on my laptop\n",
    "# so kaggle determines if I am also evaluating the kaggle test set\n",
    "kaggle = False\n",
    "\n",
    "#sim refers to if data simulating variable situations is being generated & tested on. \n",
    "sim = False\n",
    "\n",
    "#Kaggle & Sim use 'test' so dont use both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Input/train.csv', low_memory=False, index_col='id')\n",
    "if kaggle: \n",
    "    if sim == False:\n",
    "        test = pd.read_csv('./Input/test.csv', low_memory=False, index_col='id')\n",
    "\n",
    "res = pd.read_csv('./Input/resources.csv', low_memory=False, index_col='id')\n",
    "train['project_submitted_datetime'] = pd.to_datetime(train['project_submitted_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = train[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_sim(n='p039565'):\n",
    "    \"\"\"\n",
    "    Makes a semi-brute forced dataset based off the entry n, with variable:\n",
    "    Months (jan-dec), \n",
    "    Pronouns (not teacher or dr), \n",
    "    Previous Entries(0:30),\n",
    "    to see what combination may have a higher success rate\n",
    "    \"\"\"\n",
    "    test = pd.DataFrame(train.loc[n]).transpose()\n",
    "    del test['project_is_approved']\n",
    "    \n",
    "    change_dict = {\"prefix\":['Mrs.','Ms.','Mr.'],\n",
    "        \"date\":['2017-01-26','2017-02-26','2017-03-26','2017-04-26','2017-05-26','2017-06-26',\n",
    "        '2017-07-26','2017-08-26','2017-09-26','2017-10-26','2017-11-26','2017-12-26',],\n",
    "        \"prev\" : [x for x in range(0,10)]}\n",
    "\n",
    "    for i in range(100):\n",
    "        test.loc[n+str(i)] = test.loc[n].transpose()\n",
    "        test.set_value(n+str(i),'teacher_prefix',np.random.choice(change_dict['prefix']))\n",
    "        test.set_value(n+str(i),'project_submitted_datetime',np.random.choice(change_dict['date']))\n",
    "        test.set_value(n+str(i),'teacher_number_of_previously_posted_projects',np.random.choice(change_dict['prev']))\n",
    "        \n",
    "    test.index.rename = 'id'\n",
    "    return(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#making a dataset which has variable situations that 'p039654' may be under\n",
    "if sim:\n",
    "    test = make_sim('p039565')\n",
    "    train = train.drop('p039565',axis=0)\n",
    "    del make_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1.1 Resource Intergration\n",
    "Here we evaluate how much each project/proposal will cost and/or how big they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res['cost'] = res['quantity'] * res['price']\n",
    "res_agg = res.groupby('id').agg({'description': ['nunique'], 'quantity': ['sum'], 'cost': ['mean', 'sum']})\n",
    "res_agg.columns = ['unique_items', 'total_quantity', 'mean_cost', 'total_cost']\n",
    "res_agg.reset_index(inplace=True)\n",
    "\n",
    "#description was dropped because the description of the project should not have an effect on its liklihood of success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = train.merge(res_agg, left_index=True, right_on='id')\n",
    "if kaggle: \n",
    "    if sim : \n",
    "        for i in res_agg.columns:\n",
    "            if i != 'id':\n",
    "                test[i] = res_agg[res_agg['id']=='p039565'].drop('id',axis=1)[i].values[0]\n",
    "    else:\n",
    "        test =  test.merge(res_agg, left_index=True, right_on='id')\n",
    "\n",
    "del res_agg\n",
    "del res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1.2 Preprocessing of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_resource[\"project_submitted_datetime\"] = pd.to_datetime(train_resource[\"project_submitted_datetime\"])\\ntrain_resource[\"month_created\"] = train_resource[\"project_submitted_datetime\"].dt.month\\nloan = train_resource.groupby([\\'school_state\\', \\'month_created\\'])[\\'price\\'].mean().unstack()\\nloan = loan.sort_values([3], ascending=False)\\nf, ax = plt.subplots(figsize=(15, 20)) \\nloan = loan.fillna(0)\\ntemp = sns.heatmap(loan, cmap=\\'Reds\\')\\nplt.show()\\n'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_resource[\"project_submitted_datetime\"] = pd.to_datetime(train_resource[\"project_submitted_datetime\"])\n",
    "train_resource[\"month_created\"] = train_resource[\"project_submitted_datetime\"].dt.month\n",
    "loan = train_resource.groupby(['school_state', 'month_created'])['price'].mean().unstack()\n",
    "loan = loan.sort_values([3], ascending=False)\n",
    "f, ax = plt.subplots(figsize=(15, 20)) \n",
    "loan = loan.fillna(0)\n",
    "temp = sns.heatmap(loan, cmap='Reds')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#gen_mon = train.groupby(['datetime_month','gender'])['project_is_approved'].mean().reset_index()\n",
    "#prev_mon = train.groupby('teacher_number_of_previously_posted_projects')['project_is_approved'].mean().reset_index()\n",
    "\n",
    "#bins = pd.cut(train['teacher_number_of_previously_posted_projects'], [0, 25, 50, 75, 100, 125, 150])\n",
    "#pros = train.groupby(bins)['project_is_approved'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#sns.barplot(pros.index,pros)\n",
    "#plt.title('Frequent Applicants')\n",
    "#plt.xlabel(\"Teacher's Previous Postings\")\n",
    "#plt.ylabel(\"Mean Approvals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train.project_is_approved.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sns.lmplot(x=\"datetime_month\", y=\"project_is_approved\", hue=\"gender\", \n",
    "#           data=gen_mon[gen_mon['gender']!='Unk'], \n",
    "#           order=3,ci=80)\n",
    "#plt.title('Approval rate, by month, by gender (ci:90)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#del gen_mon\n",
    "#del prev_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Cat Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are 51 States, because of 50 + DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "project_essay_3    9648\n",
       "project_essay_4    9648\n",
       "dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()[train.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nahel/anaconda3/envs/NN/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train.teacher_prefix[train.teacher_prefix.isnull()] = 'Teacher'\n",
    "try: \n",
    "    test.teacher_prefix[test.teacher_prefix.isnull()] = 'Teacher'\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "fill na did not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def date_prep(train):\n",
    "    train['datetime_year'] = train['project_submitted_datetime'].dt.year\n",
    "    train['datetime_month'] = train['project_submitted_datetime'].dt.month\n",
    "    return(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gender_features(train):\n",
    "    conditions = [(train.teacher_prefix == 'Mr.'), \n",
    "                  (train.teacher_prefix == 'Mrs.') | (train.teacher_prefix == 'Ms.')]\n",
    "    choices = ['Male', 'Female']\n",
    "    train['gender'] = np.select(conditions, choices, default='Unk')\n",
    "    return(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "date_prep(train)\n",
    "if kaggle: date_prep(test)\n",
    "\n",
    "train = gender_features(train)\n",
    "if kaggle: test = gender_features(test)\n",
    "    \n",
    "del train['project_submitted_datetime']\n",
    "del train['project_subject_subcategories']\n",
    "del date_prep, gender_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3c145971da47b7ad76589f9ab5c5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Because of memory issues, it made more sense to encode everything as a string rather than dummies\n",
    "cols  = ['gender',\n",
    "        'teacher_prefix', \n",
    "        'school_state',\n",
    "        'project_grade_category',\n",
    "         'datetime_year',\n",
    "         'datetime_month',]\n",
    "\n",
    "for c in tqdm_notebook(cols):\n",
    "    dummies = pd.get_dummies(train[c])\n",
    "    train = train.join(dummies)\n",
    "    del train[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Num Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_features  = ['teacher_number_of_previously_posted_projects',\n",
    "                 'total_quantity', 'mean_cost', 'total_cost','unique_items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SS = StandardScaler()\n",
    "train[num_features] = SS.fit_transform(train[num_features])\n",
    "if kaggle: test[num_features] = SS.fit_transform(test[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del num_features, StandardScaler, SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "other_stopwords = [x for x in 'abcdefghijklmnopqrstuvwxyz']\n",
    "for j in ['student','students','education',]:\n",
    "    other_stopwords.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import gensim\n",
    "from nltk.corpus import stopwords\n",
    "def scrub(text):\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub('\\W+',' ', text)    \n",
    "    text = re.sub(r'_', ' ', text)\n",
    "    text = re.sub(r'\\t', ' ', text)\n",
    "    text = re.sub(r'\\:', ' ', text)\n",
    "    text = re.sub(r'\\+', ' ', text)\n",
    "    text = re.sub(r'\\=', ' ', text)\n",
    "    text = re.sub(r'(\\\")', ' ', text)\n",
    "    text = re.sub(r'(\\r)', ' ', text)\n",
    "    text = re.sub(r'(\\n)', ' ', text)\n",
    "    text = re.sub(r'(\\\\)', ' ', text)\n",
    "    text = re.sub('n t ','n\\'t ', text)\n",
    "    text = re.sub(' re ',' are ', text)\n",
    "    text = re.sub(r'(\\r\\n)', ' ', text)\n",
    "    text = re.sub(r'\\\"\\\"\\\"\\\"', ' ', text)\n",
    "    text = re.sub(' i m ',' i\\'m ', text)\n",
    "    return(text)\n",
    "def swords(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in (other_stopwords + stopwords.words(\"english\"))])\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Project Category Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ctv = CountVectorizer()\n",
    "project_cats = train.project_subject_categories.apply(lambda x: scrub(x))\n",
    "x = ctv.fit_transform(project_cats)\n",
    "train = train.reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = train().merge(pd.DataFrame(x.toarray(), \n",
    "                         columns=[\"subject_cat_\"+nm for nm in ctv.get_feature_names()])\n",
    "            ,left_index=True,\n",
    "            right_index=True)\n",
    "del ctv, x ,project_cats, train['project_subject_categories']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Essay Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "  \n",
    "#### Before May 17th, 2016:\n",
    "\n",
    "- project_essay_1: \"Introduce us to your classroom\"\n",
    "- project_essay_2: \"Tell us more about your students\"\n",
    "- project_essay_3: \"Describe how your students will use the materials you're requesting\"\n",
    "- project_essay_4: \"Close by sharing why your project will make a difference\"\n",
    "\n",
    "#### May 17th, 2016 and beyond:\n",
    "\n",
    "- project_essay_1: \"Describe your students: What makes your students special? Specific details about their background, your neighborhood, and your school are all helpful.\"\n",
    "- project_essay_2: \"About your project: How will these materials make a difference in your students' learning and improve their school lives?\"\n",
    "\n",
    "#### Plan\n",
    "- Combine essay_1 and essay_2 before May 17th to make \"student_description\" and use essay_1 after May 17th directly\n",
    "- Combine essay_3 and essay_4 before May 17th to make \"project_description\" and use essay_2 after May 17th directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def essay_convert(train):\n",
    "    # Making the First essay : student_description\n",
    "    train['student_description']=train['project_essay_1']\n",
    "    train.loc[train.project_essay_3.notnull(),'student_description']=train.loc[train.project_essay_3.notnull(),'project_essay_1']+train.loc[train.project_essay_3.notnull(),'project_essay_2']\n",
    "\n",
    "    # Making the second essay : project_description\n",
    "    train['project_description']=train['project_essay_2']\n",
    "    train.loc[train.project_essay_3.notnull(),'project_description']=train.loc[train.project_essay_3.notnull(),'project_essay_3']+train.loc[train.project_essay_3.notnull(),'project_essay_4']\n",
    "\n",
    "    # Removing original essays\n",
    "    del train['project_essay_1']\n",
    "    del train['project_essay_2']\n",
    "    del train['project_essay_3']\n",
    "    del train['project_essay_4']\n",
    "    return(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "essay_convert(train)\n",
    "if kaggle: essay_convert(test)\n",
    "gc.collect()\n",
    "\n",
    "del essay_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Scrub Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_features = ['project_title', 'project_resource_summary',\n",
    "                'project_description', 'student_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9461b4792455454da24ea59036fc716d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for j in tqdm_notebook(text_features):\n",
    "    n_col = 'processed_'+j\n",
    "    train[n_col] = train[j].apply(lambda x: scrub(x)).apply(lambda x: swords(x))\n",
    "    if kaggle: test[n_col] = test[j].apply(lambda x: scrub(x)).apply(lambda x: swords(x))\n",
    "\n",
    "gc.collect()\n",
    "for i in text_features:\n",
    "    del train[i]\n",
    "    if kaggle: del test[i]\n",
    "\n",
    "del stopwords, other_stopwords, text_features, swords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tfidf & X,y Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'processed_project_title',\n",
    "    'processed_project_resource_summary', \n",
    "    'processed_project_description',\n",
    "    'processed_student_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length in processed_project_title is 25 words\n",
      "Average length in processed_project_resource_summary is 80 words\n",
      "Average length in processed_project_description is 524 words\n",
      "Average length in processed_student_description is 413 words\n"
     ]
    }
   ],
   "source": [
    "for i in cols:\n",
    "    print(\"Average length in {} is {} words\".format(i,str(round(train[i].str.len().mean()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_features = [\n",
    "    100, \n",
    "    200, \n",
    "    1500,\n",
    "    1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39afebad98f4e6c9e341128ab8d7f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for c_i, c in tqdm_notebook(enumerate(cols)):\n",
    "    tfidf = TfidfVectorizer(\n",
    "        ngram_range=(1,3),\n",
    "        max_features=n_features[c_i])\n",
    "\n",
    "    tfidf.fit(train[c])\n",
    "\n",
    "#    tfidf_train2 = tfidf.transform(train[c])\n",
    "\n",
    "    tfidf_train = np.array(tfidf.transform(train[c].values).toarray(), dtype=np.float16)\n",
    "    for i in range(n_features[c_i]):\n",
    "        train[c + '_tfidf_' + str(i)] = tfidf_train[:, i]\n",
    "    if kaggle:\n",
    "        tfidf_test = np.array(tfidf.transform(test[c].values).toarray(), dtype=np.float16)\n",
    "        for i in range(n_features[c_i]):\n",
    "            test[c + '_tfidf_' + str(i)] = tfidf_test[:, i]\n",
    "\n",
    "for i in cols:\n",
    "    del train[i]\n",
    "    if kaggle: del test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#did this a while ago\n",
    "#train = train.reset_index()\n",
    "del train['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "drop_cols = ['project_is_approved','id','teacher_id']\n",
    "\n",
    "X = train.drop(drop_cols, axis=1)\n",
    "y = train['project_is_approved']\n",
    "feature_names = list(X.columns)\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#if running demo, uncomment this and change test['id'].vaues -> test['index'].values\n",
    "#test = test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#X_test = test.drop(drop_cols, axis=1, errors='ignore')\n",
    "#id_test = test['id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Keras Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500,)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3400"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.callbacks import EarlyStopping, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.01)\n",
    "l2 = regularizers.l2(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1028,input_shape=(X_train.shape[1],), \n",
    "                activation='relu',\n",
    "                kernel_regularizer = l2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(256, \n",
    "                activation='relu',\n",
    "                kernel_regularizer = l2))\n",
    "\n",
    "model.add(Dense(1, \n",
    "                activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = adam)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=1, patience=10)\n",
    "\n",
    "callbacks_list = [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/5\n",
      "7500/7500 [==============================] - 67s 9ms/step - loss: 20.7933 - val_loss: 0.4315\n",
      "roc-auc: 0.6183 - roc-auc_val: 0.5781                                                                                                    \n",
      "Epoch 2/5\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.4333 - val_loss: 0.4233\n",
      "roc-auc: 0.6072 - roc-auc_val: 0.5815                                                                                                    \n",
      "Epoch 3/5\n",
      "7500/7500 [==============================] - 76s 10ms/step - loss: 0.4280 - val_loss: 0.4258\n",
      "roc-auc: 0.4355 - roc-auc_val: 0.4622                                                                                                    \n",
      "Epoch 4/5\n",
      "7500/7500 [==============================] - 70s 9ms/step - loss: 0.4274 - val_loss: 0.4281\n",
      "roc-auc: 0.6017 - roc-auc_val: 0.6129                                                                                                    \n",
      "Epoch 5/5\n",
      "7500/7500 [==============================] - 68s 9ms/step - loss: 0.4254 - val_loss: 0.4251\n",
      "roc-auc: 0.5981 - roc-auc_val: 0.5966                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                    epochs=5,\n",
    "                    callbacks=[roc_callback(training_data=(X_train, y_train),\n",
    "                                            validation_data=(X_test, y_test))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#p = model.predict(X_test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idf = tfidf.idf_\n",
    "idf_map = dict(zip(tfidf.get_feature_names(), idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfidf.get_feature_names()[75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfidf.idf_[75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#idf_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_test,'pred':p})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#submit.sort_values('pred',axis=0,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NN]",
   "language": "python",
   "name": "conda-env-NN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
