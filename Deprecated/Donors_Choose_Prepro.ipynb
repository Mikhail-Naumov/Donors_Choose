{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from tqdm import tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Kaggle : Generate an X Kaggle test set\n",
    "\n",
    "One_Hot = False\n",
    "#Default - Label Encoding for LGBM\n",
    "#One Hot - for Neural Nets\n",
    "\"\"\"\n",
    "def date_prep(train):\n",
    "    train['project_submitted_datetime'] = pd.to_datetime(train['project_submitted_datetime'])\n",
    "    train['datetime_year'] = train['project_submitted_datetime'].dt.year\n",
    "    train['datetime_month'] = train['project_submitted_datetime'].dt.month\n",
    "    return(train)\n",
    "\n",
    "def gender_features(train):\n",
    "    conditions = [(train.teacher_prefix == 'Mr.'), \n",
    "                  (train.teacher_prefix == 'Mrs.') | (train.teacher_prefix == 'Ms.')]\n",
    "    choices = ['Male', 'Female']\n",
    "    train['gender'] = np.select(conditions, choices, default='Unk')\n",
    "    return(train)\n",
    "\n",
    "def scrub(text):\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub('\\W+',' ', text)    \n",
    "    text = re.sub(r'_', ' ', text)\n",
    "    text = re.sub(r'\\t', ' ', text)\n",
    "    text = re.sub(r'\\:', ' ', text)\n",
    "    text = re.sub(r'\\+', ' ', text)\n",
    "    text = re.sub(r'\\=', ' ', text)\n",
    "    text = re.sub(r'(\\\")', ' ', text)\n",
    "    text = re.sub(r'(\\r)', ' ', text)\n",
    "    text = re.sub(r'(\\n)', ' ', text)\n",
    "    text = re.sub(r'(\\\\)', ' ', text)\n",
    "    text = re.sub('n t ','n\\'t ', text)\n",
    "    text = re.sub(' re ',' are ', text)\n",
    "    text = re.sub(r'(\\r\\n)', ' ', text)\n",
    "    text = re.sub(r'\\\"\\\"\\\"\\\"', ' ', text)\n",
    "    text = re.sub(' i m ',' i\\'m ', text)\n",
    "    return(text)\n",
    "\n",
    "def swords(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in (all_stopwords)])\n",
    "    return(text)\n",
    "\n",
    "def cat(text):\n",
    "    text =[word for word in text.split(',')]\n",
    "    text =[word.strip() for word in text]\n",
    "    return(text)\n",
    "\n",
    "def essay_convert(train):\n",
    "    # Making the First essay : student_description\n",
    "    train['student_description']=train['project_essay_1']\n",
    "    train.loc[train.project_essay_3.notnull(),'student_description']=train.loc[train.project_essay_3.notnull(),'project_essay_1']+train.loc[train.project_essay_3.notnull(),'project_essay_2']\n",
    "\n",
    "    # Making the second essay : project_description\n",
    "    train['project_description']=train['project_essay_2']\n",
    "    train.loc[train.project_essay_3.notnull(),'project_description']=train.loc[train.project_essay_3.notnull(),'project_essay_3']+train.loc[train.project_essay_3.notnull(),'project_essay_4']\n",
    "\n",
    "    # Removing original essays\n",
    "    del train['project_essay_1']\n",
    "    del train['project_essay_2']\n",
    "    del train['project_essay_3']\n",
    "    del train['project_essay_4']\n",
    "    return(train)\n",
    "\n",
    "print(\"Importing Datasets\")\n",
    "train = pd.read_csv('./Input/train.csv', low_memory=False, index_col='id')\n",
    "if kaggle: \n",
    "    test = pd.read_csv('./Input/test.csv', low_memory=False, index_col='id')\n",
    "\n",
    "res = pd.read_csv('./Input/resources.csv', low_memory=False, index_col='id')\n",
    "\n",
    "\n",
    "\n",
    "print('Precessing Resources & Merging Datasets')\n",
    "res['cost'] = res['quantity'] * res['price']\n",
    "res_agg = res.groupby('id').agg({'description': ['nunique'], 'quantity': ['sum'], 'cost': ['mean', 'sum','median','max','min']})\n",
    "res_agg.columns = ['unique_items','total_quantity', 'mean_cost', 'total_cost','median_cost','most_exp_cost','least_exp_cost']\n",
    "res_agg.reset_index(inplace=True)\n",
    "\n",
    "#description was dropped because the description of the project \n",
    "#should not have an effect on its liklihood of success,\n",
    "#outside of the effect of the project essay\n",
    "\n",
    "train = train.merge(res_agg, left_index=True, right_on='id')\n",
    "if kaggle: \n",
    "    test =  test.merge(res_agg, left_index=True, right_on='id')\n",
    "\n",
    "del res, res_agg\n",
    "\n",
    "\n",
    "\n",
    "print('Date & Prefix Preprocessing')\n",
    "\n",
    "date_prep(train)\n",
    "train.teacher_prefix[train.teacher_prefix.isnull()] = 'Teacher'\n",
    "train = gender_features(train)\n",
    "\n",
    "if kaggle: \n",
    "    date_prep(test)\n",
    "    test.teacher_prefix[test.teacher_prefix.isnull()] = 'Teacher'\n",
    "    test = gender_features(test)\n",
    "    del test['project_submitted_datetime'], test['project_subject_subcategories']\n",
    "\n",
    "del train['project_submitted_datetime'], train['project_subject_subcategories']\n",
    "del date_prep, gender_features\n",
    "\n",
    "print('Encoding Categorical Features')\n",
    "# Because of trees do no need onehot encoding, label encoding is used\n",
    "cols  = ['gender',\n",
    "        'teacher_prefix', \n",
    "        'school_state',\n",
    "        'datetime_year',\n",
    "        'datetime_month',\n",
    "        'project_grade_category']\n",
    "\n",
    "train.merge(pd.get_dummies(train[cols]))\n",
    "\n",
    "if One_Hot:\n",
    "    train.merge(pd.get_dummies(train[cols]))\n",
    "\n",
    "for c in tqdm_notebook(cols):\n",
    "    encod = LabelEncoder()\n",
    "    encod.fit(train[c].astype(str))\n",
    "    train[c] = encod.transform(train[c].astype(str))\n",
    "    if kaggle:        \n",
    "        test[c] = encod.transform(test[c].astype(str))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Scaling Numeric Features')\n",
    "num_features  = ['teacher_number_of_previously_posted_projects',\n",
    "                 'total_quantity', 'mean_cost', 'total_cost','unique_items']\n",
    "\n",
    "SS = StandardScaler()\n",
    "train[num_features] = SS.fit_transform(train[num_features])\n",
    "if kaggle: test[num_features] = SS.transform(test[num_features])\n",
    "\n",
    "del num_features, StandardScaler, SS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Text Processing')\n",
    "\n",
    "all_stopwords = [x for x in 'abcdefghijklmnopqrstuvwxyz']\n",
    "for j in ['student','students','education',]:\n",
    "    all_stopwords.append(j)\n",
    "all_stopwords += stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "##############\n",
    "#because there are some entries list as having multiple categories,\n",
    "#they are one hot encoded to allow for the acceptance of those features\n",
    "#\n",
    "#this is an awkward place in the code to put this process....\n",
    "\n",
    "clean_cats = train.project_subject_categories.apply(lambda x:cat(x))\n",
    "p = pd.get_dummies(clean_cats.apply(pd.Series).stack()).sum(level=0).reset_index(drop=True)\n",
    "del p['Warmth']\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "train = train.merge(p,left_index=True,right_index=True)\n",
    "\n",
    "if kaggle:\n",
    "    clean_cats = test.project_subject_categories.apply(lambda x:cat(x))\n",
    "    for i in p.columns:\n",
    "        test[i]=0\n",
    "    p = pd.get_dummies(clean_cats.apply(pd.Series).stack()).sum(level=0).reset_index(drop=True)\n",
    "    if p.columns.contains('Warmth'):\n",
    "        del(p['Warmth'])\n",
    "    for i in p.columns:\n",
    "        test[i] = p[i]\n",
    "    del test['project_subject_categories']\n",
    "\n",
    "del train['project_subject_categories'], p, cat\n",
    "\n",
    "#######################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Essay Conversion & Scrub')\n",
    "\n",
    "text_features = ['project_title', 'project_resource_summary',\n",
    "                'project_description', 'student_description']\n",
    "\n",
    "essay_convert(train)\n",
    "if kaggle: essay_convert(test)\n",
    "\n",
    "for j in tqdm_notebook(text_features):\n",
    "    n_col = 'processed_'+j\n",
    "    train[n_col] = train[j].apply(lambda x: scrub(x)).apply(lambda x: swords(x))\n",
    "#    del train[i]\n",
    "    if kaggle: \n",
    "        test[n_col] = test[j].apply(lambda x: scrub(x)).apply(lambda x: swords(x))\n",
    "#        del test[i]\n",
    "\n",
    "for i in text_features:\n",
    "    del train[i]\n",
    "    if kaggle: del test[i]\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "del essay_convert, stopwords, all_stopwords, text_features, swords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Tf-idf processing')\n",
    "\n",
    "cols = [\n",
    "    'processed_project_title',\n",
    "    'processed_project_resource_summary', \n",
    "    'processed_project_description',\n",
    "    'processed_student_description']\n",
    "\n",
    "n_features = [100, 100, 2000, 2000]\n",
    "\n",
    "for c_i, c in tqdm_notebook(enumerate(cols)):\n",
    "    tfidf = TfidfVectorizer(\n",
    "        ngram_range=(1,2),\n",
    "        max_features=n_features[c_i])\n",
    "\n",
    "    tfidf.fit(train[c])\n",
    "\n",
    "    tfidf_train = np.array(tfidf.transform(train[c].values).toarray(), dtype=np.float16)\n",
    "    for i in range(n_features[c_i]):\n",
    "        train[c + '_contains_-' + tfidf.get_feature_names()[i]] = tfidf_train[:, i]\n",
    "    if kaggle:\n",
    "        tfidf_test = np.array(tfidf.transform(test[c].values).toarray(), dtype=np.float16)\n",
    "        for i in range(n_features[c_i]):\n",
    "            test[c + '_contains_-' + tfidf.get_feature_names()[i]] = tfidf_test[:, i]\n",
    "\n",
    "for i in cols:\n",
    "    del train[i]\n",
    "    if kaggle: del test[i]\n",
    "\n",
    "if kaggle: del tfidf_test\n",
    "del tfidf_train, tfidf\n",
    "\n",
    "\n",
    "\n",
    "print('Assigning X & y')\n",
    "drop_cols = ['project_is_approved','id','teacher_id']\n",
    "\n",
    "X = train.drop(drop_cols, axis=1)\n",
    "y = train['project_is_approved']\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "if kaggle: \n",
    "    return X, y, feature_names, kaggle\n",
    "else: \n",
    "    return X, y, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ok(x=False):\n",
    "    \n",
    "    if x: return 6\n",
    "    else: return 6,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
