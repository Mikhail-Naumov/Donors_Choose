{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Predicting Donors Choose</center>\n",
    "\n",
    "--------\n",
    "\n",
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desk = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Input/train.csv', low_memory=False, index_col='id')\n",
    "if desk: test = pd.read_csv('./Input/test.csv', low_memory=False, index_col='id')\n",
    "\n",
    "res = pd.read_csv('./Input/resources.csv', low_memory=False, index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[:500]\n",
    "test = test[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Resource Intergration\n",
    "Here we evaluate how much each project/proposal will cost and/or how big they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res['cost'] = res['quantity'] * res['price']\n",
    "res_agg = res.groupby('id').agg({'description': ['nunique'], 'quantity': ['sum'], 'cost': ['mean', 'sum']})\n",
    "res_agg.columns = ['unique_items', 'total_quantity', 'mean_cost', 'total_cost']\n",
    "res_agg.reset_index(inplace=True)\n",
    "\n",
    "#description was dropped because the description of the project should not have an effect on its liklihood of success\n",
    "\n",
    "train = train.merge(res_agg, left_index=True, right_on='id')\n",
    "if desk: test =  test.merge(res_agg, left_index=True, right_on='id')\n",
    "\n",
    "del res_agg\n",
    "del res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Preprocessing of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cat Preprocessing\n",
    "- Improve states\n",
    "    - States are 51 because of 50 + DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "teacher_id                                        0\n",
       "teacher_prefix                                    0\n",
       "school_state                                      0\n",
       "project_submitted_datetime                        0\n",
       "project_grade_category                            0\n",
       "project_subject_categories                        0\n",
       "project_subject_subcategories                     0\n",
       "project_title                                     0\n",
       "project_essay_1                                   0\n",
       "project_essay_2                                   0\n",
       "project_essay_3                                 482\n",
       "project_essay_4                                 482\n",
       "project_resource_summary                          0\n",
       "teacher_number_of_previously_posted_projects      0\n",
       "project_is_approved                               0\n",
       "id                                                0\n",
       "unique_items                                      0\n",
       "total_quantity                                    0\n",
       "mean_cost                                         0\n",
       "total_cost                                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leno/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/leno/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train.teacher_prefix[train.teacher_prefix.isnull()] = 'Teacher'\n",
    "if desk: test.teacher_prefix[test.teacher_prefix.isnull()] = 'Teacher'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill na did not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_prep(train):\n",
    "    train['project_submitted_datetime'] = pd.to_datetime(train['project_submitted_datetime'])\n",
    "    train['datetime_year'] = train['project_submitted_datetime'].dt.year\n",
    "    train['datetime_month'] = train['project_submitted_datetime'].dt.month\n",
    "\n",
    "    del train['project_submitted_datetime']\n",
    "    del train['project_subject_subcategories']\n",
    "    return(train)\n",
    "\n",
    "date_prep(train)\n",
    "if desk: date_prep(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_features(train):\n",
    "    conditions = [(train.teacher_prefix == 'Mr.'), \n",
    "                  (train.teacher_prefix == 'Mrs.') | (train.teacher_prefix == 'Ms.')]\n",
    "    choices = ['Male', 'Female']\n",
    "    train['gender'] = np.select(conditions, choices, default='Unk')\n",
    "    return(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = gender_features(train)\n",
    "if desk: test = gender_features(test)\n",
    "del gender_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train.groupby(['datetime_month','gender'])['project_is_approved'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gen_mon.to_csv('gb_gender_month.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sns.lmplot(x=\"datetime_month\", y=\"project_is_approved\", hue=\"gender\", data=gen_mon[gen_mon['gender']!='Unk'], order=4, ci=None, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b29ca6c474242a782a8d7d44045fc5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c9122dff2545eeb175a4179905a203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Because of memory issues, it made more sense to encode everything as a string rather than dummies\n",
    "cols  = [\n",
    "    'teacher_id', \n",
    "    'gender',\n",
    "#    'datetime_year', already encoded\n",
    "#    'datetime_month', already encoded\n",
    "    'teacher_prefix', \n",
    "    'school_state', \n",
    "    'project_grade_category',\n",
    "    'project_subject_categories']\n",
    "\n",
    "for c in tqdm.tqdm_notebook(cols):\n",
    "    encod = LabelEncoder()\n",
    "    encod.fit(train[c].astype(str))\n",
    "    train[c] = encod.transform(train[c].astype(str))\n",
    "\n",
    "if desk: \n",
    "    for c in tqdm.tqdm_notebook(cols):\n",
    "        encod = LabelEncoder()\n",
    "        encod.fit(test[c].astype(str))\n",
    "        test[c] = encod.transform(test[c].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del cols\n",
    "del encod\n",
    "del LabelEncoder\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features  = ['teacher_number_of_previously_posted_projects','total_quantity', 'mean_cost', 'total_cost',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS = StandardScaler()\n",
    "train[num_features] = SS.fit_transform(train[num_features])\n",
    "if desk: test[num_features] = SS.fit_transform(test[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del num_features\n",
    "del StandardScaler\n",
    "del SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "#### Before May 17th, 2016:\n",
    "\n",
    "- project_essay_1: \"Introduce us to your classroom\"\n",
    "- project_essay_2: \"Tell us more about your students\"\n",
    "- project_essay_3: \"Describe how your students will use the materials you're requesting\"\n",
    "- project_essay_4: \"Close by sharing why your project will make a difference\"\n",
    "\n",
    "#### May 17th, 2016 and beyond:\n",
    "\n",
    "- project_essay_1: \"Describe your students: What makes your students special? Specific details about their background, your neighborhood, and your school are all helpful.\"\n",
    "- project_essay_2: \"About your project: How will these materials make a difference in your students' learning and improve their school lives?\"\n",
    "\n",
    "#### Plan\n",
    "- Combine essay_1 and essay_2 before May 17th to make \"student_description\" and use essay_1 after May 17th directly\n",
    "- Combine essay_3 and essay_4 before May 17th to make \"project_description\" and use essay_2 after May 17th directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def essay_convert(train):\n",
    "    # Making the First essay : student_description\n",
    "    train['student_description']=train['project_essay_1']\n",
    "    train.loc[train.project_essay_3.notnull(),'student_description']=train.loc[train.project_essay_3.notnull(),'project_essay_1']+train.loc[train.project_essay_3.notnull(),'project_essay_2']\n",
    "\n",
    "    # Making the second essay : project_description\n",
    "    train['project_description']=train['project_essay_2']\n",
    "    train.loc[train.project_essay_3.notnull(),'project_description']=train.loc[train.project_essay_3.notnull(),'project_essay_3']+train.loc[train.project_essay_3.notnull(),'project_essay_4']\n",
    "\n",
    "    # Removing original essays\n",
    "    del train['project_essay_1']\n",
    "    del train['project_essay_2']\n",
    "    del train['project_essay_3']\n",
    "    del train['project_essay_4']\n",
    "    return(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_convert(train)\n",
    "if desk: essay_convert(test)\n",
    "gc.collect()\n",
    "del essay_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lem & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_features = ['project_title', 'project_resource_summary',\n",
    "                'project_description', 'student_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_stopwords = [x for x in 'abcdefghijklmnopqrstuvwxyz']\n",
    "for j in ['student','students','education',]:\n",
    "    other_stopwords.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import gensim\n",
    "from nltk.corpus import stopwords\n",
    "def scrub(text):\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub('\\W+',' ', text)\n",
    "    text = re.sub(r'(\\\")', ' ', text)\n",
    "    text = re.sub(r'(\\r)', ' ', text)\n",
    "    text = re.sub(r'(\\n)', ' ', text)\n",
    "    text = re.sub(r'(\\r\\n)', ' ', text)\n",
    "    text = re.sub(r'(\\\\)', ' ', text)\n",
    "    text = re.sub(r'\\t', ' ', text)\n",
    "    text = re.sub(r'\\:', ' ', text)\n",
    "    text = re.sub(r'\\\"\\\"\\\"\\\"', ' ', text)\n",
    "    text = re.sub(r'_', ' ', text)\n",
    "    text = re.sub(r'\\+', ' ', text)\n",
    "    text = re.sub(r'\\=', ' ', text)\n",
    "    text = re.sub(' i m ',' i\\'m ', text)\n",
    "    text = re.sub('n t ','n\\'t ', text)\n",
    "    text = re.sub(' re ',' are ', text)\n",
    "    text = ' '.join([word for word in text.split() if word not in (other_stopwords + stopwords.words(\"english\"))])\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0df20383de94f96887c9986bfee2faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for j in tqdm.tqdm_notebook(text_features):\n",
    "    n_col = 'processed_'+j\n",
    "    train[n_col] = train[j].apply(lambda x: scrub(x))\n",
    "    if desk: test[n_col] = test[j].apply(lambda x: scrub(x))\n",
    "\n",
    "gc.collect()\n",
    "for i in text_features:\n",
    "    del train[i]\n",
    "    if desk: del test[i]\n",
    "\n",
    "del stopwords\n",
    "del other_stopwords\n",
    "del text_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf & X,y Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'processed_project_title',\n",
    "    'processed_project_resource_summary', \n",
    "    'processed_project_description',\n",
    "    'processed_student_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length in processed_project_title is 24 words\n",
      "Average length in processed_project_resource_summary is 80 words\n",
      "Average length in processed_project_description is 513 words\n",
      "Average length in processed_student_description is 402 words\n"
     ]
    }
   ],
   "source": [
    "for i in cols:\n",
    "    print(\"Average length in {} is {} words\".format(i,str(round(train[i].str.len().mean()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = [\n",
    "    200, \n",
    "    400, \n",
    "    2500,\n",
    "    2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3891bb6c4b94af8bcc9bea0d3b642d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for c_i, c in tqdm.tqdm_notebook(enumerate(cols)):\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=n_features[c_i])\n",
    "\n",
    "    tfidf.fit(train[c])\n",
    "\n",
    "#    tfidf_train2 = tfidf.transform(train[c])\n",
    "\n",
    "    tfidf_train = np.array(tfidf.transform(train[c].values).toarray(), dtype=np.float16)\n",
    "    for i in range(n_features[c_i]):\n",
    "        train[c + '_tfidf_' + str(i)] = tfidf_train[:, i]\n",
    "    if desk:\n",
    "        tfidf_test = np.array(tfidf.transform(test[c].values).toarray(), dtype=np.float16)\n",
    "        for i in range(n_features[c_i]):\n",
    "            test[c + '_tfidf_' + str(i)] = tfidf_test[:, i]\n",
    "\n",
    "for i in cols:\n",
    "    del train[i]\n",
    "    if desk: del test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index()\n",
    "del train['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['project_is_approved','unique_items','id','teacher_id']\n",
    "\n",
    "X = train.drop(drop_cols, axis=1)\n",
    "y = train['project_is_approved']\n",
    "\n",
    "#del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test.drop(drop_cols, axis=1, errors='ignore')\n",
    "id_test = test['id'].values\n",
    "feature_names = list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search over Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gb_tuned_parameters = {\n",
    "#                        \"n_estimators\": [x for x in range(100, 400, 2)],\n",
    "#                        'min_samples_split' : [3],\n",
    "#                        'max_depth': [20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rs = RandomizedSearchCV(GradientBoostingClassifier(),\n",
    "#                        gb_tuned_parameters,\n",
    "#                        n_iter=30, \n",
    "#                        scoring='roc_auc', \n",
    "#                        cv=StratifiedKFold(), \n",
    "#                        verbose=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] n_estimators=386, min_samples_split=3, max_depth=20 .............\n",
      "[CV]  n_estimators=386, min_samples_split=3, max_depth=20, score=0.49051094890510955, total=   7.9s\n",
      "[CV] n_estimators=386, min_samples_split=3, max_depth=20 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=386, min_samples_split=3, max_depth=20, score=0.6020681265206813, total=   9.9s\n",
      "[CV] n_estimators=386, min_samples_split=3, max_depth=20 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.8s remaining:    0.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-242-8a5aa4857eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 788\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#rs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search over LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier( \n",
    "    boosting_type=\"gbdt\",\n",
    "    is_unbalance=True, \n",
    "    random_state=10,\n",
    "    bagging_freq=5, \n",
    "    learning_rate=0.025,\n",
    "    min_child_samples=3,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_opt = {'n_estimators':  range(50, 100, 5),\n",
    "             'max_depth': range(15, 30),\n",
    "             'feature_fraction': [x / 1000.0 for x in range(825,900,25)],\n",
    "             'bagging_fraction': [x / 1000.0 for x in range(825,900,25)],\n",
    "             'num_leaves':range(20,50,5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   21.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59484470173672288"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RandomizedSearchCV(\n",
    "    model, \n",
    "    params_opt, \n",
    "    n_iter=10,\n",
    "    scoring='roc_auc',\n",
    "    verbose=1,\n",
    "    cv=3)\n",
    "rs.fit(X,y)\n",
    "rs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's auc: 0.767922\tvalid_1's auc: 0.605263\n",
      "[20]\ttraining's auc: 0.795065\tvalid_1's auc: 0.595192\n",
      "[30]\ttraining's auc: 0.805931\tvalid_1's auc: 0.596816\n",
      "[40]\ttraining's auc: 0.819221\tvalid_1's auc: 0.611761\n",
      "[50]\ttraining's auc: 0.850108\tvalid_1's auc: 0.658869\n",
      "[60]\ttraining's auc: 0.864264\tvalid_1's auc: 0.646849\n",
      "[70]\ttraining's auc: 0.874156\tvalid_1's auc: 0.674464\n",
      "[80]\ttraining's auc: 0.893074\tvalid_1's auc: 0.658869\n",
      "[90]\ttraining's auc: 0.902511\tvalid_1's auc: 0.677713\n",
      "[100]\ttraining's auc: 0.918788\tvalid_1's auc: 0.688759\n",
      "[110]\ttraining's auc: 0.928268\tvalid_1's auc: 0.687459\n",
      "[120]\ttraining's auc: 0.936017\tvalid_1's auc: 0.688759\n",
      "[130]\ttraining's auc: 0.943117\tvalid_1's auc: 0.701105\n",
      "[140]\ttraining's auc: 0.945368\tvalid_1's auc: 0.712151\n",
      "[150]\ttraining's auc: 0.952814\tvalid_1's auc: 0.717349\n",
      "[160]\ttraining's auc: 0.959177\tvalid_1's auc: 0.717349\n",
      "[170]\ttraining's auc: 0.964459\tvalid_1's auc: 0.720598\n",
      "[180]\ttraining's auc: 0.964286\tvalid_1's auc: 0.723847\n",
      "[190]\ttraining's auc: 0.967013\tvalid_1's auc: 0.729045\n",
      "[200]\ttraining's auc: 0.970996\tvalid_1's auc: 0.734243\n",
      "[210]\ttraining's auc: 0.96961\tvalid_1's auc: 0.747888\n",
      "[220]\ttraining's auc: 0.973074\tvalid_1's auc: 0.74399\n",
      "[230]\ttraining's auc: 0.973766\tvalid_1's auc: 0.744639\n",
      "[240]\ttraining's auc: 0.973766\tvalid_1's auc: 0.744639\n",
      "[250]\ttraining's auc: 0.973766\tvalid_1's auc: 0.744639\n",
      "[260]\ttraining's auc: 0.973766\tvalid_1's auc: 0.744639\n",
      "[270]\ttraining's auc: 0.973766\tvalid_1's auc: 0.744639\n",
      "[280]\ttraining's auc: 0.973766\tvalid_1's auc: 0.744639\n",
      "[290]\ttraining's auc: 0.973766\tvalid_1's auc: 0.744639\n",
      "[300]\ttraining's auc: 0.973766\tvalid_1's auc: 0.744639\n",
      "[310]\ttraining's auc: 0.973766\tvalid_1's auc: 0.744639\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's auc: 0.96961\tvalid_1's auc: 0.747888\n",
      "Fold 2/5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's auc: 0.75355\tvalid_1's auc: 0.52924\n",
      "[20]\ttraining's auc: 0.814156\tvalid_1's auc: 0.576998\n",
      "[30]\ttraining's auc: 0.843766\tvalid_1's auc: 0.568876\n",
      "[40]\ttraining's auc: 0.877273\tvalid_1's auc: 0.58577\n",
      "[50]\ttraining's auc: 0.87974\tvalid_1's auc: 0.593892\n",
      "[60]\ttraining's auc: 0.894372\tvalid_1's auc: 0.624431\n",
      "[70]\ttraining's auc: 0.900563\tvalid_1's auc: 0.62963\n",
      "[80]\ttraining's auc: 0.898268\tvalid_1's auc: 0.623782\n",
      "[90]\ttraining's auc: 0.906494\tvalid_1's auc: 0.62898\n",
      "[100]\ttraining's auc: 0.914502\tvalid_1's auc: 0.669266\n",
      "[110]\ttraining's auc: 0.915238\tvalid_1's auc: 0.663418\n",
      "[120]\ttraining's auc: 0.930087\tvalid_1's auc: 0.653671\n",
      "[130]\ttraining's auc: 0.935974\tvalid_1's auc: 0.65627\n",
      "[140]\ttraining's auc: 0.939134\tvalid_1's auc: 0.668616\n",
      "[150]\ttraining's auc: 0.945065\tvalid_1's auc: 0.683561\n",
      "[160]\ttraining's auc: 0.95013\tvalid_1's auc: 0.680962\n",
      "[170]\ttraining's auc: 0.953983\tvalid_1's auc: 0.673164\n",
      "[180]\ttraining's auc: 0.957013\tvalid_1's auc: 0.679662\n",
      "[190]\ttraining's auc: 0.96\tvalid_1's auc: 0.680312\n",
      "[200]\ttraining's auc: 0.961515\tvalid_1's auc: 0.681611\n",
      "[210]\ttraining's auc: 0.962165\tvalid_1's auc: 0.68551\n",
      "[220]\ttraining's auc: 0.962727\tvalid_1's auc: 0.684211\n",
      "[230]\ttraining's auc: 0.962727\tvalid_1's auc: 0.684211\n",
      "[240]\ttraining's auc: 0.962727\tvalid_1's auc: 0.684211\n",
      "[250]\ttraining's auc: 0.962727\tvalid_1's auc: 0.684211\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's auc: 0.946104\tvalid_1's auc: 0.68551\n",
      "Fold 3/5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's auc: 0.737831\tvalid_1's auc: 0.553862\n",
      "[20]\ttraining's auc: 0.820176\tvalid_1's auc: 0.675136\n",
      "[30]\ttraining's auc: 0.830772\tvalid_1's auc: 0.672764\n",
      "[40]\ttraining's auc: 0.85466\tvalid_1's auc: 0.640921\n",
      "[50]\ttraining's auc: 0.881973\tvalid_1's auc: 0.677507\n",
      "[60]\ttraining's auc: 0.891348\tvalid_1's auc: 0.682927\n",
      "[70]\ttraining's auc: 0.906674\tvalid_1's auc: 0.698509\n",
      "[80]\ttraining's auc: 0.923456\tvalid_1's auc: 0.711382\n",
      "[90]\ttraining's auc: 0.92885\tvalid_1's auc: 0.705285\n",
      "[100]\ttraining's auc: 0.926581\tvalid_1's auc: 0.704607\n",
      "[110]\ttraining's auc: 0.928935\tvalid_1's auc: 0.696477\n",
      "[120]\ttraining's auc: 0.933216\tvalid_1's auc: 0.704607\n",
      "[130]\ttraining's auc: 0.937026\tvalid_1's auc: 0.716802\n",
      "[140]\ttraining's auc: 0.935571\tvalid_1's auc: 0.724255\n",
      "[150]\ttraining's auc: 0.940751\tvalid_1's auc: 0.715447\n",
      "[160]\ttraining's auc: 0.94576\tvalid_1's auc: 0.701897\n",
      "[170]\ttraining's auc: 0.950768\tvalid_1's auc: 0.705285\n",
      "[180]\ttraining's auc: 0.95338\tvalid_1's auc: 0.704607\n",
      "[190]\ttraining's auc: 0.958517\tvalid_1's auc: 0.699187\n",
      "[200]\ttraining's auc: 0.961086\tvalid_1's auc: 0.699187\n",
      "[210]\ttraining's auc: 0.962456\tvalid_1's auc: 0.694444\n",
      "[220]\ttraining's auc: 0.96237\tvalid_1's auc: 0.693089\n",
      "[230]\ttraining's auc: 0.96237\tvalid_1's auc: 0.693089\n",
      "[240]\ttraining's auc: 0.96237\tvalid_1's auc: 0.693089\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's auc: 0.937026\tvalid_1's auc: 0.72832\n",
      "Fold 4/5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's auc: 0.777773\tvalid_1's auc: 0.559072\n",
      "[20]\ttraining's auc: 0.795136\tvalid_1's auc: 0.538577\n",
      "[30]\ttraining's auc: 0.824216\tvalid_1's auc: 0.53918\n",
      "[40]\ttraining's auc: 0.837992\tvalid_1's auc: 0.554551\n",
      "[50]\ttraining's auc: 0.856086\tvalid_1's auc: 0.54792\n",
      "[60]\ttraining's auc: 0.872918\tvalid_1's auc: 0.544907\n",
      "[70]\ttraining's auc: 0.89821\tvalid_1's auc: 0.553948\n",
      "[80]\ttraining's auc: 0.911366\tvalid_1's auc: 0.55214\n",
      "[90]\ttraining's auc: 0.92275\tvalid_1's auc: 0.529234\n",
      "[100]\ttraining's auc: 0.92873\tvalid_1's auc: 0.544304\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's auc: 0.773786\tvalid_1's auc: 0.566305\n",
      "Fold 5/5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's auc: 0.763419\tvalid_1's auc: 0.442708\n",
      "[20]\ttraining's auc: 0.824092\tvalid_1's auc: 0.514205\n",
      "[30]\ttraining's auc: 0.884404\tvalid_1's auc: 0.555398\n",
      "[40]\ttraining's auc: 0.89536\tvalid_1's auc: 0.529356\n",
      "[50]\ttraining's auc: 0.901632\tvalid_1's auc: 0.495265\n",
      "[60]\ttraining's auc: 0.904628\tvalid_1's auc: 0.539773\n",
      "[70]\ttraining's auc: 0.915283\tvalid_1's auc: 0.550189\n",
      "[80]\ttraining's auc: 0.925777\tvalid_1's auc: 0.571023\n",
      "[90]\ttraining's auc: 0.936271\tvalid_1's auc: 0.571023\n",
      "[100]\ttraining's auc: 0.940131\tvalid_1's auc: 0.567235\n",
      "[110]\ttraining's auc: 0.944031\tvalid_1's auc: 0.569129\n",
      "[120]\ttraining's auc: 0.947972\tvalid_1's auc: 0.589962\n",
      "[130]\ttraining's auc: 0.947891\tvalid_1's auc: 0.570076\n",
      "[140]\ttraining's auc: 0.952595\tvalid_1's auc: 0.580492\n",
      "[150]\ttraining's auc: 0.955571\tvalid_1's auc: 0.583333\n",
      "[160]\ttraining's auc: 0.955088\tvalid_1's auc: 0.589962\n",
      "[170]\ttraining's auc: 0.955732\tvalid_1's auc: 0.579545\n",
      "[180]\ttraining's auc: 0.95541\tvalid_1's auc: 0.579545\n",
      "[190]\ttraining's auc: 0.95541\tvalid_1's auc: 0.579545\n",
      "[200]\ttraining's auc: 0.95541\tvalid_1's auc: 0.579545\n",
      "[210]\ttraining's auc: 0.95541\tvalid_1's auc: 0.579545\n",
      "[220]\ttraining's auc: 0.95541\tvalid_1's auc: 0.579545\n",
      "[230]\ttraining's auc: 0.95541\tvalid_1's auc: 0.579545\n",
      "[240]\ttraining's auc: 0.95541\tvalid_1's auc: 0.579545\n",
      "[250]\ttraining's auc: 0.95541\tvalid_1's auc: 0.579545\n",
      "[260]\ttraining's auc: 0.95541\tvalid_1's auc: 0.579545\n",
      "Early stopping, best iteration is:\n",
      "[164]\ttraining's auc: 0.954003\tvalid_1's auc: 0.597538\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "cnt = 0\n",
    "n_splits = 5\n",
    "n_repeats = 1\n",
    "kf = RepeatedKFold(\n",
    "    n_splits=n_splits, \n",
    "    n_repeats=n_repeats, \n",
    "    random_state=42)\n",
    "\n",
    "for train_index, valid_index in kf.split(X):\n",
    "    print('Fold {}/{}'.format(cnt + 1, n_splits))\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'max_depth': 20,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.025,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'num_threads': 1,\n",
    "        'lambda_l2': 1.0,\n",
    "        'min_gain_to_split': 3,\n",
    "    }  \n",
    "\n",
    "    lgb_train = lgb.Dataset(\n",
    "        X.loc[train_index], \n",
    "        y.loc[train_index], \n",
    "        feature_name=feature_names)\n",
    "\n",
    "    lgb_valid = lgb.Dataset(\n",
    "        X.loc[valid_index], \n",
    "        y.loc[valid_index])\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=10,)\n",
    "\n",
    "    cnt = cnt+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(X_test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_test,'pred':p})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
