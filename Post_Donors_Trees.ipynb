{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Post_Donors_PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "import GPyOpt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Post_Donor_PrePro : Preprocessing function that pulls from the original data\n",
    "#Diet : Pull from a previously saved preprocessed csv, as to only do scaling and text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y, df_cols, le_dict = Post_Donors_PreProcess.Post_Donor_PrePro(\n",
    "#                            Tf_Features=100, Sample=1, \n",
    "#                            One_Hot=False, Standard_Scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding\n",
      "Scaling\n",
      "Text Processing\n"
     ]
    }
   ],
   "source": [
    "X, y, df_cols, le_dict = Post_Donors_PreProcess.Diet_Prepro(\n",
    "                            Tf_Features=100, \n",
    "                            One_Hot=False, \n",
    "                            Standard_Scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_train_data = lgbm.Dataset(data=X#.drop('School Percentage Free Lunch',axis=1)\n",
    "                               ,label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbm.LGBMClassifier()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbm.LGBMClassifier(\n",
    "    boosting_type = 'dart',\n",
    "    application= 'binary',\n",
    "    learning_rate= 0.01,\n",
    "    scale_pos_weight= 2,\n",
    "    drop_rate= 0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rand2 = {'n_estimators': [x for x in range(50,200,20)],\n",
    "             'feature_fraction': [x / 1000.0 for x in range(820,900,20)],\n",
    "             'bagging_fraction': [x / 1000.0 for x in range(820,900,20)],\n",
    "             'lambda_l2' : [x / 100.0 for x in range(0,310,10)],\n",
    "             'boosting_type': ['dart','gbdt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(\n",
    "    model, \n",
    "    params_rand2, \n",
    "    n_iter=5,\n",
    "    scoring='roc_auc',\n",
    "    cv=5)\n",
    "\n",
    "rs.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bay Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_bay = [{'name': 'feature_fraction','type': 'continuous', 'domain': (0.5,0.9)},\n",
    "              {'name': 'bagging_fraction','type': 'continuous', 'domain': (0.5,0.9)},\n",
    "              {'name': 'lambda_l2',       'type': 'continuous', 'domain': (0.1,0.5)},\n",
    "              {'name': 'n_estimators',      'type': 'discrete', 'domain': (100,300)}\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bay_Wrapper(x):\n",
    "    \"\"\"\n",
    "    Model Wrapper for Bay Opt \n",
    "    Wrapper used for LGBM & Bay:\n",
    "    x[0][:] = list of all params for this aq\n",
    "    \"\"\"\n",
    "    AUC = True\n",
    "    if AUC: metric = 'auc'\n",
    "    else: metric = 'binary_logloss'\n",
    "    \n",
    "    lgbm_params = { 'feature_fraction': x[0][0],\n",
    "                    'bagging_fraction': x[0][1],\n",
    "                    'lambda_l2' : x[0][2],\n",
    "                    'boosting': 'dart',\n",
    "                   \n",
    "                   \n",
    "                    'n_estimators' : int(x[0][3]),\n",
    "                    #'num_leaves': int(x[0][3]),\n",
    "                    'max_depth': -1,\n",
    "                                 #int(x[0][4]),\n",
    "                   \n",
    "                    'application': 'binary',\n",
    "                    'learning_rate': 0.01,\n",
    "                    'scale_pos_weight': 2,\n",
    "                    'drop_rate': 0.2,\n",
    "}\n",
    "\n",
    "    cv_results = lgbm.cv(train_set=lgbm_train_data,\n",
    "                         params=lgbm_params, \n",
    "                         nfold=5,\n",
    "                         num_boost_round = 600,\n",
    "                         early_stopping_rounds=50,\n",
    "                         metrics=[metric])\n",
    "\n",
    "    optimum_boost_rounds = np.argmax(cv_results[metric+'-mean'])\n",
    "    print('{} : {}'.format(metric,np.max(cv_results['{}-mean'.format(metric)])))\n",
    "    \n",
    "    return np.max(cv_results[metric+'-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay = GPyOpt.methods.BayesianOptimization(Bay_Wrapper,\n",
    "                                          params_bay,\n",
    "                                          acquisition_type ='EI',   # LCB acquisition\n",
    "                                          acquisition_weight = .5,  # Exploration exploitation\n",
    "                                          maximize=True\n",
    "                                         )\n",
    "bay.run_optimization(50) #GPyOpt uses 5 points + the number listed\n",
    "print('Function after 5 Aquisitions')\n",
    "bay.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay.plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_pred = bay.x_opt\n",
    "print('feature_fraction: '+str(round(bay_pred[0],5)))\n",
    "print('bagging_fraction: '+str(round(bay_pred[1],5)))\n",
    "print('lambda_l2: '+str(round(bay_pred[2],5)))\n",
    "print('n_estimators: '+str(round(bay_pred[3],5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = { 'boosting': 'dart',\n",
    "                'application': 'binary',\n",
    "                'learning_rate': 0.01,\n",
    "                'scale_pos_weight': 2,\n",
    "                'drop_rate': 0.2,\n",
    "                'n_estimators': int(bay_pred[3]),\n",
    "                'feature_fraction': bay_pred[0],\n",
    "                'bagging_fraction': bay_pred[1],\n",
    "                'lambda_l2' : bay_pred[2]}\n",
    "\n",
    "cv_results = lgbm.cv(train_set=lgbm_train_data,\n",
    "                     params=lgbm_params, \n",
    "                     nfold=5,\n",
    "                     num_boost_round=600,\n",
    "                     early_stopping_rounds=50,\n",
    "                     #metrics=['accuracy']\n",
    "                    )\n",
    "#'binary_logloss-mean'\n",
    "optimum_boost_rounds = np.argmax(cv_results['binary_logloss-mean'])\n",
    "print('Auc : {}'.format(np.max(cv_results['binary_logloss-mean'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
