{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tf_Features = 100\n",
    "One_Hot =  False\n",
    "Standard_Scale = True\n",
    "N_Gram = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_cleaner(df,col):\n",
    "    \"\"\"\n",
    "    Takes in the df and the column containing messy, sub cats.\n",
    "\n",
    "    pd.get_dummies:\n",
    "       col                 A | A,B | B | B,A\n",
    "    0|  A              0|  1    0    0    0\n",
    "    1| A,B  -onehot->  1|  0    1    0    0\n",
    "    2|  B              2|  0    0    1    0\n",
    "    3| B,A             3|  0    0    0    1\n",
    "\n",
    "    this:\n",
    "\n",
    "       col                       A | B\n",
    "    0|  A                    0|  1   0\n",
    "    1| A,B  -cat_cleaner ->  1|  1   1\n",
    "    2|  B                    2|  0   1\n",
    "    3| B,A                   3|  1   1\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def cat(text):\n",
    "        text =[word for word in text.split(',')]\n",
    "        text =[word.strip() for word in text]\n",
    "        return(text)\n",
    "\n",
    "\n",
    "    df[col] = df[col].astype('str')\n",
    "    clean_cats = df[col].apply(lambda x:cat(x))\n",
    "    p = pd.get_dummies(clean_cats.apply(pd.Series).stack()).sum(level=0).reset_index(drop=True)\n",
    "    return p\n",
    "\n",
    "def text_cleaner(text,all_stop):\n",
    "    \"\"\"\n",
    "    clean_str = text_cleaner(dirty_string)\n",
    "    \"\"\"\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.replace('<!--DONOTREMOVEESSAYDIVIDER-->',' ')\n",
    "    text = text.replace('\\n' , ' ')\n",
    "    text = regex.sub('',text)\n",
    "    text = ' '.join([word for word in text.split() if word not in all_stop])\n",
    "    return(text)\n",
    "\n",
    "def plot_empties(bad_form):\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    i = 1\n",
    "    for j in bad_form:\n",
    "        plt.subplot(230+i)\n",
    "        sns.heatmap(pd.DataFrame(bad_form[j].isnull().sum()/bad_form[j].shape[0]*100),\n",
    "                    annot=True,cmap=sns.color_palette(\"cool\"),linewidth=1,linecolor=\"white\")\n",
    "        plt.title(j)\n",
    "        i+=1\n",
    "\n",
    "    plt.subplots_adjust(wspace = 1.6)\n",
    "    return\n",
    "\n",
    "def compress(df,encode=[],num=[],byte_str = False):\n",
    "    pre_ = df[num+encode].memory_usage(deep=True)\n",
    "\n",
    "    for i in num:\n",
    "        if df[i].astype(np.float16).memory_usage(deep=True)<df[i].memory_usage(deep=True):\n",
    "            df[i] = df[i].astype(np.float16)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if byte_str:\n",
    "        for j in encode:\n",
    "            if df[j].astype(np.string_).memory_usage(deep=True)<df[j].memory_usage(deep=True):\n",
    "                df[j] = df[j].astype(np.string_)\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        for j in encode:\n",
    "            if df[j].astype(str).memory_usage(deep=True)<df[j].memory_usage(deep=True):\n",
    "                df[j] = df[j].astype(str)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "    post_ = df[num+encode].memory_usage(deep=True)\n",
    "    print(\"Data Usage - change:{}\".format((post_-pre_)))\n",
    "    print(\"Total Change: {}\".format((post_-pre_).sum()))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import string\n",
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Null values from all data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#plot_empties(bad_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Donor Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    bad_form['Donations'] = bad_form['Donations'][bad_form['Donations']['Donation Amount'] > 0.1]\n",
    "    Donors = bad_form['Donations'].groupby('Donor ID').agg({'Donation ID': ['nunique'], \n",
    "         'Donation Amount': ['mean', 'sum','median','max','min','std']})\n",
    "\n",
    "    Donors = bad_form['Donors'].merge(Donors, right_index=True, left_on='Donor ID').copy(deep=True)\n",
    "    Donors['One Time Donor'] = Donors['Donations Count'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    Donors['Donation Std Amount'] = Donors['Donation Std Amount'].fillna(0)\n",
    "\n",
    "    Donors.columns = ['Donor ID', 'Donor City', 'Donor State', 'Donor Is Teacher', 'Donor Zip', 'Donations Count', \n",
    "                    'Donation Mean Amount', 'Donation Sum Amount', 'Donation Median Amount', 'Donation Max Amount', \n",
    "                    'Donation Min Amount', 'Donation Std Amount', 'One Time Donor']\n",
    "\n",
    "    Donors.to_csv('./Input/New/Donors_Clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Treating Nulls in 'Teachers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bad_form['Teachers']['Teacher Prefix'] = bad_form['Teachers']['Teacher Prefix'].apply(\n",
    "    lambda x: 'Teacher' if x in ['Mx.', np.nan] else x)\n",
    "\n",
    "for i in bad_form:\n",
    "    bad_form[i] = bad_form[i].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data Aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bad_form['Projects'] = pd.read_csv('./Input/New/Projects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#How much of the data do you want to use?\n",
    "df = bad_form['Projects'][:int(bad_form['Projects'].shape[0] * Sample)].copy(deep=True)\n",
    "del bad_form['Projects']\n",
    "#if Sample: df = bad_form['Projects'][:1000].copy(deep=True)\n",
    "#else: df = bad_form['Projects'].copy(deep=True)\n",
    "for i in ['Teacher Project Posted Sequence', 'Project Fully Funded Date', 'Project Expiration Date', \n",
    "          'Project Subject Subcategory Tree',  'Project Title', 'Project Short Description']:\n",
    "    del df[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Init\n",
      "x\n",
      "xx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('DataFrame Init')\n",
    "\n",
    "#Structure Target\n",
    "df = df[df['Project Current Status'] != 'Live']\n",
    "df['Project Current Status'] = df['Project Current Status'].apply(lambda x: 1 if x == 'Fully Funded' else 0)\n",
    "\n",
    "#Adding dt features\n",
    "df['Project Posted Date']  = pd.to_datetime(df['Project Posted Date'])\n",
    "df['Project Posted Year']  = df['Project Posted Date'].dt.year.astype(str)\n",
    "df['Project Posted Month'] = df['Project Posted Date'].dt.month\n",
    "df['Project Posted Month'] = df['Project Posted Month'].apply(lambda x: calendar.month_abbr[x])\n",
    "\n",
    "#cols\n",
    "encode_cols = ['Project Type','Project Posted Year','Project Posted Month',\n",
    "               'Project Grade Level Category','Project Resource Category',]\n",
    "num_cols    = ['Project Cost']\n",
    "\n",
    "#del\n",
    "del df['Project Posted Date'], calendar\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Teachers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Teacher Information\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Teacher First Project Posted Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Teacher First Project Posted Date'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-68bee6f40de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#del\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Teacher ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Teacher First Project Posted Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mbad_form\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Teachers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2094\u001b[0m             \u001b[0;31m# there was no match, this call should raise the appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m             \u001b[0;31m# exception:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m         \u001b[0;31m# delete from the caches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3900\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mselected\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \"\"\"\n\u001b[0;32m-> 3902\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3904\u001b[0m         \u001b[0mis_deleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Teacher First Project Posted Date'"
     ]
    }
   ],
   "source": [
    "print('Merging Teacher Information')\n",
    "\n",
    "#Treating Nulls in 'Teachers'\n",
    "bad_form['Teachers']['Teacher Prefix'] = bad_form['Teachers']['Teacher Prefix'].apply(lambda x: 'Teacher' if x in ['Mx.', np.nan] else x)\n",
    "\n",
    "del bad_form['Teachers']['Teacher First Project Posted Date']\n",
    "\n",
    "#merging teacher to df\n",
    "df = df.merge(bad_form['Teachers'],on='Teacher ID')\n",
    "\n",
    "#cols\n",
    "encode_cols += ['Teacher Prefix']\n",
    "num_cols    += []\n",
    "\n",
    "#del\n",
    "del bad_form['Teachers'], df['Teacher ID']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging School Information\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Merging School Information')\n",
    "\n",
    "for i in ['School Name','School City','School County']:\n",
    "    del bad_form['Schools'][i]\n",
    "\n",
    "#very few, dropping nulls\n",
    "bad_form['Schools'] = bad_form['Schools'].dropna()\n",
    "\n",
    "#merging school to df\n",
    "df = df.merge(bad_form['Schools'],on='School ID')\n",
    "df['School Zip'] = df['School Zip'].astype(str)\n",
    "\n",
    "#cols\n",
    "encode_cols += ['School Metro Type','School State','School District','School Zip']\n",
    "num_cols    += ['School Percentage Free Lunch']\n",
    "\n",
    "#del\n",
    "del bad_form['Schools'], df['School ID']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Resource Managment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Resource Managment\n",
      "x\n",
      "xx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Merging Resource Managment')\n",
    "\n",
    "#more funding features\n",
    "bad_form['Resources']['Resource Total Cost'] = bad_form['Resources']['Resource Quantity'] * bad_form['Resources']['Resource Unit Price']\n",
    "funding_agg = bad_form['Resources'].groupby('Project ID').agg(\n",
    "    {'Resource Item Name': ['nunique'], \n",
    "     'Resource Quantity': ['sum'], \n",
    "     'Resource Total Cost': ['mean', 'sum','median','max','min']})\n",
    "\n",
    "funding_agg.columns = ['Project num Unique Resources',\n",
    "                   'Total Resource Quantity', \n",
    "                   'Mean Resource Cost', \n",
    "                   'Total Project Cost',\n",
    "                   'Median Resource Cost',\n",
    "                   'Most exp Resource Cost',\n",
    "                   'Least exp Resource Cost']\n",
    "\n",
    "#cols\n",
    "encode_cols += []\n",
    "num_cols    += list(funding_agg.columns.values)\n",
    "\n",
    "#merging funding to df\n",
    "funding_agg.reset_index(inplace=True)\n",
    "df = df.merge(funding_agg,on='Project ID')\n",
    "\n",
    "del funding_agg, df['Project ID'], \n",
    "#del bad_form['Resources']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_csv('./Input/Processed/df_no_encode_yes_essay.csv')\n",
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding / Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "print('Preprocessing')\n",
    "df = df.dropna()\n",
    "\n",
    "#Encoding\n",
    "le_dict = {}\n",
    "if One_Hot:\n",
    "    df = df.merge(pd.get_dummies(df[encode_cols])\n",
    "             ,left_index=True,right_index=True)\n",
    "    for i in encode_cols:\n",
    "        del df[i]\n",
    "else:\n",
    "    for c in encode_cols:\n",
    "        encod = LabelEncoder()\n",
    "        encod.fit(df[c].astype(str))\n",
    "        df[c] = encod.transform(df[c].astype(str))\n",
    "        le_dict[c] = dict(zip(encod.classes_, encod.transform(encod.classes_)))\n",
    "    del encod\n",
    "\n",
    "#already done in import\n",
    "#p = cat_cleaner(df,'Project Subject Category Tree')\n",
    "#df = df.merge(p,left_index=True,right_index=True)\n",
    "#del df['Project Subject Category Tree'], p\n",
    "\n",
    "#Scaling\n",
    "df = df.dropna()\n",
    "\n",
    "if Standard_Scale:\n",
    "    Scalar = StandardScaler()\n",
    "else:\n",
    "    Scalar = MinMaxScaler()\n",
    "\n",
    "df[num_cols] = Scalar.fit_transform(df[num_cols])\n",
    "\n",
    "#del One_Hot, LabelEncoder, Standard_Scale, Scalar\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Text Processing')\n",
    "\n",
    "text_cols = ['Project Essay','Project Need Statement']\n",
    "\n",
    "#adding more words to 'stopwords'\n",
    "extra_words = ['student','students','education']\n",
    "single_l = [x for x in 'abcdefghijklmnopqrstuvwxyz']\n",
    "for j in single_l:\n",
    "    extra_words.append(j)\n",
    "extra_words += stopwords.words(\"english\")\n",
    "\n",
    "for i in text_cols:\n",
    "    df[i] = df[i].apply(lambda x: text_cleaner(x,extra_words))\n",
    "\n",
    "del text_cleaner, extra_words, single_l, stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfidf = TfidfVectorizer(max_features=Tf_Features, ngram_range=(1,N_Gram))\n",
    "for i in text_cols:\n",
    "    tfidf.fit(df[i])\n",
    "    tf_cols = [str(i)+' contains: \"'+str(x)+'\"' for x in list(tfidf.vocabulary_.keys())]\n",
    "    df = df.merge(pd.DataFrame(tfidf.transform(df[i]).todense(),columns=tf_cols), left_index=True, right_index=True)\n",
    "\n",
    "for i in text_cols:\n",
    "    del df[i]\n",
    "del tfidf, tf_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Project Current Status'],axis=1)\n",
    "y = df['Project Current Status']\n",
    "df_cols = df.columns\n",
    "#le_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Donors = pd.read_csv('./Input/New/Donors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Donors['Likely Organization'] = Donors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Donors['Donation Mean Amount'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
