{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Post_Donor_PrePro(Tf_Features=100,Sample=True,One_Hot=True,Standard_Scale=True)\n",
    "    \"\"\"\n",
    "    Tf_Features : Max TFIDF Features (100)\n",
    "    Sample : Only Use 1000 submissions (True)\n",
    "    One_Hot : One Hot Encode (True)\n",
    "                Label Encode (False)\n",
    "                \n",
    "    Standard_Scale : Standard Scale (True)\n",
    "                     MinMaxScalar  (False)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #### Func\n",
    "\n",
    "    def cat_cleaner(df,col):\n",
    "        \"\"\"\n",
    "        Takes in the df and the column containing messy, sub cats.\n",
    "\n",
    "        pd.get_dummies:\n",
    "           col                 A | A,B | B | B,A\n",
    "        0|  A              0|  1    0    0    0\n",
    "        1| A,B  -onehot->  1|  0    1    0    0\n",
    "        2|  B              2|  0    0    1    0\n",
    "        3| B,A             3|  0    0    0    1\n",
    "\n",
    "        this:\n",
    "\n",
    "           col                       A | B\n",
    "        0|  A                    0|  1   0\n",
    "        1| A,B  -cat_cleaner ->  1|  1   1\n",
    "        2|  B                    2|  0   1\n",
    "        3| B,A                   3|  1   1\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        def cat(text):\n",
    "            text =[word for word in text.split(',')]\n",
    "            text =[word.strip() for word in text]\n",
    "            return(text)\n",
    "\n",
    "\n",
    "        df[col] = df[col].astype('str')\n",
    "        clean_cats = df[col].apply(lambda x:cat(x))\n",
    "        p = pd.get_dummies(clean_cats.apply(pd.Series).stack()).sum(level=0).reset_index(drop=True)\n",
    "        return p\n",
    "\n",
    "    def text_cleaner(text,all_stop):\n",
    "        \"\"\"\n",
    "        clean_str = text_cleaner(dirty_string)\n",
    "        \"\"\"\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "        text = text.lower()\n",
    "        text = text.replace('<!--DONOTREMOVEESSAYDIVIDER-->',' ')\n",
    "        text = text.replace('\\n' , ' ')\n",
    "        text = regex.sub('',text)\n",
    "        text = ' '.join([word for word in text.split() if word not in all_stop])\n",
    "        return(text)\n",
    "\n",
    "    def plot_empties(bad_form):\n",
    "        plt.figure(figsize=(15,15))\n",
    "\n",
    "        i = 1\n",
    "        for j in tqdm_notebook(bad_form):\n",
    "            plt.subplot(230+i)\n",
    "            sns.heatmap(pd.DataFrame(bad_form[j].isnull().sum()/bad_form[j].shape[0]*100),\n",
    "                        annot=True,cmap=sns.color_palette(\"cool\"),linewidth=1,linecolor=\"white\")\n",
    "            plt.title(j)\n",
    "            i+=1\n",
    "\n",
    "        plt.subplots_adjust(wspace = 1.6)\n",
    "        return\n",
    "\n",
    "    def compress(df,encode=[],num=[],byte_str = False):\n",
    "        pre_ = df[num+encode].memory_usage(deep=True)\n",
    "\n",
    "        for i in num:\n",
    "            if df[i].astype(np.float16).memory_usage(deep=True)<df[i].memory_usage(deep=True):\n",
    "                df[i] = df[i].astype(np.float16)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        if byte_str:\n",
    "            for j in encode:\n",
    "                if df[j].astype(np.string_).memory_usage(deep=True)<df[j].memory_usage(deep=True):\n",
    "                    df[j] = df[j].astype(np.string_)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            for j in encode:\n",
    "                if df[j].astype(str).memory_usage(deep=True)<df[j].memory_usage(deep=True):\n",
    "                    df[j] = df[j].astype(str)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "\n",
    "\n",
    "        post_ = df[num+encode].memory_usage(deep=True)\n",
    "        print(\"Data Usage - change:{}\".format((post_-pre_)))\n",
    "        print(\"Total Change: {}\".format((post_-pre_).sum()))\n",
    "        return\n",
    "\n",
    "    ### Imports\n",
    "\n",
    "    import gc\n",
    "    import re\n",
    "    import calendar\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from tqdm import tqdm_notebook\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    bad_form = {#'Donations' : pd.read_csv('./Input/New/Donations.csv'),\n",
    "                #'Donors'    : pd.read_csv('./Input/New/Donors.csv'),\n",
    "\n",
    "                'Projects'  : pd.read_csv('./Input/New/Projects.csv'),\n",
    "                'Resources' : pd.read_csv('./Input/New/Resources.csv'),\n",
    "                'Schools'   : pd.read_csv('./Input/New/Schools.csv'),\n",
    "                'Teachers'  : pd.read_csv('./Input/New/Teachers.csv')}\n",
    "\n",
    "    ### Data Aggregation\n",
    "\n",
    "    #How much of the data do you want to use?\n",
    "    if Sample: df = bad_form['Projects'][:1000].copy(deep=True)\n",
    "    else: df = bad_form['Projects'].copy(deep=True)\n",
    "\n",
    "    #Projects\n",
    "    print('DataFrame Init')\n",
    "\n",
    "    #Structure Target\n",
    "    df['Project Current Status'] = df['Project Current Status'].apply(lambda x: 1 if x == 'Fully Funded' else 0)\n",
    "\n",
    "    #Adding dt features\n",
    "    df['Project Posted Date'] = pd.to_datetime(df['Project Posted Date'])\n",
    "    df['Project Posted Year'] = df['Project Posted Date'].dt.year.astype(str)\n",
    "    df['Project Posted Month'] = df['Project Posted Date'].dt.month\n",
    "    df['Project Posted Month'] = df['Project Posted Month'].apply(lambda x: calendar.month_abbr[x])\n",
    "\n",
    "    #cols\n",
    "    encode_cols = ['Project Type','Project Posted Year','Project Posted Month',\n",
    "                   'Project Grade Level Category','Project Resource Category',]\n",
    "    num_cols    = ['Project Cost']\n",
    "\n",
    "    #del\n",
    "    for i in ['Teacher Project Posted Sequence', 'Project Fully Funded Date', \n",
    "              'Project Expiration Date', 'Project Subject Subcategory Tree', \n",
    "              'Project Posted Date','Project Title','Project Short Description']:\n",
    "        del df[i]\n",
    "    del calendar\n",
    "    gc.collect()\n",
    "\n",
    "    #Null values from all data sources\n",
    "\n",
    "    #plot_empties(bad_form)\n",
    "    del plot_empties\n",
    "\n",
    "    #Teachers\n",
    "    print('Merging Teacher Information')\n",
    "\n",
    "    #Treating Nulls in 'Teachers'\n",
    "    bad_form['Teachers']['Teacher Prefix'] = bad_form['Teachers']['Teacher Prefix'].apply(\n",
    "        lambda x: 'Teacher' if x in ['Mx.', np.nan] else x)\n",
    "\n",
    "    #merging teacher to df\n",
    "    df = df.merge(bad_form['Teachers'],on='Teacher ID').copy(deep=True)\n",
    "\n",
    "    #cols\n",
    "    encode_cols += ['Teacher Prefix']\n",
    "    num_cols    += []\n",
    "\n",
    "    #del\n",
    "    for i in ['Teacher ID','Teacher First Project Posted Date']:\n",
    "        del df[i]\n",
    "    gc.collect()\n",
    "\n",
    "    #School\n",
    "    print('Merging School Information')\n",
    "\n",
    "    #very few, dropping nulls\n",
    "    bad_form['Schools'] = bad_form['Schools'].dropna()\n",
    "\n",
    "    #merging school to df\n",
    "    df = df.merge(bad_form['Schools'],on='School ID')\n",
    "    df['School Zip'] = df['School Zip'].astype(str)\n",
    "\n",
    "    #cols\n",
    "    encode_cols += ['School Metro Type','School State','School District','School Zip']\n",
    "    num_cols    += ['School Percentage Free Lunch']\n",
    "\n",
    "    #del\n",
    "    for i in ['School Name','School ID','School City','School County']:\n",
    "        del df[i]\n",
    "    gc.collect()\n",
    "\n",
    "    # Resource Management\n",
    "    print('Merging Resource Managment')\n",
    "\n",
    "    #more funding features\n",
    "    bad_form['Resources']['Resource Total Cost'] = bad_form['Resources']['Resource Quantity'] * bad_form['Resources']['Resource Unit Price']\n",
    "    funding_agg = bad_form['Resources'].groupby('Project ID').agg(\n",
    "        {'Resource Item Name': ['nunique'], \n",
    "         'Resource Quantity': ['sum'], \n",
    "         'Resource Total Cost': ['mean', 'sum','median','max','min']})\n",
    "\n",
    "    funding_agg.columns = ['Project num Unique Resources',\n",
    "                       'Total Resource Quantity', \n",
    "                       'Mean Resource Cost', \n",
    "                       'Total Project Cost',\n",
    "                       'Median Resource Cost',\n",
    "                       'Most exp Resource Cost',\n",
    "                       'Least exp Resource Cost']\n",
    "\n",
    "    #cols\n",
    "    encode_cols += []\n",
    "    num_cols    += list(funding_agg.columns.values)\n",
    "\n",
    "    #merging funding to df\n",
    "    funding_agg.reset_index(inplace=True)\n",
    "    df = df.merge(funding_agg,on='Project ID')\n",
    "\n",
    "    del funding_agg\n",
    "    gc.collect()\n",
    "\n",
    "    del df['Project ID']\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    #s = set(encode_cols+num_cols)\n",
    "    #df[[x for x in df.columns if x not in s]].head(5)\n",
    "\n",
    "\n",
    "\n",
    "    #compressing data\n",
    "    print('Compressing Data')\n",
    "    compress(df,encode_cols,num_cols)\n",
    "\n",
    "    del compress\n",
    "    gc.collect()\n",
    "\n",
    "    del bad_form\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### Encoding / Scaling\n",
    "\n",
    "    #Preprocessing\n",
    "    print('Preprocessing')\n",
    "\n",
    "    #Encoding\n",
    "    if One_Hot:\n",
    "        df.merge(pd.get_dummies(df[encode_cols])\n",
    "                 ,left_index=True,right_index=True)\n",
    "        for i in encode_cols:\n",
    "            del df[i]\n",
    "    else:\n",
    "        for c in tqdm_notebook(encode_cols):\n",
    "            encod = LabelEncoder()\n",
    "            encod.fit(df[c].astype(str))\n",
    "            df[c] = encod.transform(df[c].astype(str))\n",
    "        del encod\n",
    "\n",
    "    p = cat_cleaner(df,'Project Subject Category Tree')\n",
    "    df = df.merge(p,left_index=True,right_index=True)\n",
    "    del df['Project Subject Category Tree'], p\n",
    "\n",
    "    #Scaling\n",
    "    if Standard_Scale:\n",
    "        Scalar = StandardScaler()\n",
    "    else:\n",
    "        Scalar = MinMaxScaler()\n",
    "\n",
    "    df[num_cols] = scalar.fit_transform(df[num_cols])\n",
    "\n",
    "    del One_Hot, LabelEncoder, Standard_Scale, Scalar\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### Text Editing\n",
    "\n",
    "    print('Text Processing')\n",
    "\n",
    "    text_cols = ['Project Essay','Project Need Statement']\n",
    "\n",
    "    #adding more words to 'stopwords'\n",
    "    extra_words = ['student','students','education']\n",
    "    single_l = [x for x in 'abcdefghijklmnopqrstuvwxyz']\n",
    "    for j in single_l:\n",
    "        extra_words.append(j)\n",
    "    extra_words += stopwords.words(\"english\")\n",
    "\n",
    "    for i in text_cols:\n",
    "        df[i] = df[i].apply(lambda x: text_cleaner(x,extra_words))\n",
    "\n",
    "    del text_cleaner, extra_words, single_l, stopwords\n",
    "\n",
    "    #Tfidf\n",
    "    tfidf = TfidfVectorizer(max_features=Tf_Features)\n",
    "\n",
    "    for i in text_cols:\n",
    "        tfidf.fit(df[i])\n",
    "        tf_cols = [str(i)+' contains: \"'+str(x)+'\"' for x in list(tfidf.vocabulary_.keys())]\n",
    "        df = df.merge(pd.DataFrame(tfidf.transform(df[i]).todense(),columns=tf_cols), left_index=True, right_index=True)\n",
    "\n",
    "    for i in text_cols:\n",
    "        del df[i]\n",
    "    del tfidf, df, tf_cols\n",
    "\n",
    "\n",
    "    X = df.drop(['Project Current Status'],axis=1)\n",
    "    y = df['Project Current Status']\n",
    "    df_cols = df.columns\n",
    "    return(X,y,df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
