{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nreturns - X, y, df_cols -\\nTf_Features : Max TFIDF Features (100)\\nSample : Only Use 1000 submissions (True)\\nOne_Hot : One Hot Encode (True)\\n            Label Encode (False)\\n\\nStandard_Scale : Standard Scale (True)\\n                 MinMaxScalar  (False)\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "returns - X, y, df_cols -\n",
    "Tf_Features : Max TFIDF Features (100)\n",
    "N_Gram : 1\n",
    "Sample : Only Use 1000 submissions (True)\n",
    "One_Hot : One Hot Encode (True)\n",
    "            Label Encode (False)\n",
    "\n",
    "Standard_Scale : Standard Scale (True)\n",
    "                 MinMaxScalar  (False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tf_Features = 100\n",
    "Sample = True\n",
    "One_Hot =  True\n",
    "Standard_Scale = True\n",
    "N_Gram = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_cleaner(df,col):\n",
    "    \"\"\"\n",
    "    Takes in the df and the column containing messy, sub cats.\n",
    "\n",
    "    pd.get_dummies:\n",
    "       col                 A | A,B | B | B,A\n",
    "    0|  A              0|  1    0    0    0\n",
    "    1| A,B  -onehot->  1|  0    1    0    0\n",
    "    2|  B              2|  0    0    1    0\n",
    "    3| B,A             3|  0    0    0    1\n",
    "\n",
    "    this:\n",
    "\n",
    "       col                       A | B\n",
    "    0|  A                    0|  1   0\n",
    "    1| A,B  -cat_cleaner ->  1|  1   1\n",
    "    2|  B                    2|  0   1\n",
    "    3| B,A                   3|  1   1\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def cat(text):\n",
    "        text =[word for word in text.split(',')]\n",
    "        text =[word.strip() for word in text]\n",
    "        return(text)\n",
    "\n",
    "\n",
    "    df[col] = df[col].astype('str')\n",
    "    clean_cats = df[col].apply(lambda x:cat(x))\n",
    "    p = pd.get_dummies(clean_cats.apply(pd.Series).stack()).sum(level=0).reset_index(drop=True)\n",
    "    return p\n",
    "\n",
    "def text_cleaner(text,all_stop):\n",
    "    \"\"\"\n",
    "    clean_str = text_cleaner(dirty_string)\n",
    "    \"\"\"\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.replace('<!--DONOTREMOVEESSAYDIVIDER-->',' ')\n",
    "    text = text.replace('\\n' , ' ')\n",
    "    text = regex.sub('',text)\n",
    "    text = ' '.join([word for word in text.split() if word not in all_stop])\n",
    "    return(text)\n",
    "\n",
    "def plot_empties(bad_form):\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    i = 1\n",
    "    for j in tqdm_notebook(bad_form):\n",
    "        plt.subplot(230+i)\n",
    "        sns.heatmap(pd.DataFrame(bad_form[j].isnull().sum()/bad_form[j].shape[0]*100),\n",
    "                    annot=True,cmap=sns.color_palette(\"cool\"),linewidth=1,linecolor=\"white\")\n",
    "        plt.title(j)\n",
    "        i+=1\n",
    "\n",
    "    plt.subplots_adjust(wspace = 1.6)\n",
    "    return\n",
    "\n",
    "def compress(df,encode=[],num=[],byte_str = False):\n",
    "    pre_ = df[num+encode].memory_usage(deep=True)\n",
    "\n",
    "    for i in num:\n",
    "        if df[i].astype(np.float16).memory_usage(deep=True)<df[i].memory_usage(deep=True):\n",
    "            df[i] = df[i].astype(np.float16)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if byte_str:\n",
    "        for j in encode:\n",
    "            if df[j].astype(np.string_).memory_usage(deep=True)<df[j].memory_usage(deep=True):\n",
    "                df[j] = df[j].astype(np.string_)\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        for j in encode:\n",
    "            if df[j].astype(str).memory_usage(deep=True)<df[j].memory_usage(deep=True):\n",
    "                df[j] = df[j].astype(str)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "    post_ = df[num+encode].memory_usage(deep=True)\n",
    "    print(\"Data Usage - change:{}\".format((post_-pre_)))\n",
    "    print(\"Total Change: {}\".format((post_-pre_).sum()))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import string\n",
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_form = {#'Donations' : pd.read_csv('./Input/New/Donations.csv'),\n",
    "            #'Donors'    : pd.read_csv('./Input/New/Donors.csv'),\n",
    "\n",
    "            'Projects'  : pd.read_csv('./Input/New/Projects.csv'),\n",
    "            'Resources' : pd.read_csv('./Input/New/Resources.csv'),\n",
    "            'Schools'   : pd.read_csv('./Input/New/Schools.csv'),\n",
    "            'Teachers'  : pd.read_csv('./Input/New/Teachers.csv')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1110015"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_form['Projects']['Project ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Aggregation\n",
    "\n",
    "#How much of the data do you want to use?\n",
    "if Sample: df = bad_form['Projects'][:1000].copy(deep=True)\n",
    "else: df = bad_form['Projects'].copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Init\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Projects\n",
    "print('DataFrame Init')\n",
    "\n",
    "#Structure Target\n",
    "df['Project Current Status'] = df['Project Current Status'].apply(lambda x: 1 if x == 'Fully Funded' else 0)\n",
    "\n",
    "#Adding dt features\n",
    "df['Project Posted Date'] = pd.to_datetime(df['Project Posted Date'])\n",
    "df['Project Posted Year'] = df['Project Posted Date'].dt.year.astype(str)\n",
    "df['Project Posted Month'] = df['Project Posted Date'].dt.month\n",
    "df['Project Posted Month'] = df['Project Posted Month'].apply(lambda x: calendar.month_abbr[x])\n",
    "\n",
    "#cols\n",
    "encode_cols = ['Project Type','Project Posted Year','Project Posted Month',\n",
    "               'Project Grade Level Category','Project Resource Category',]\n",
    "num_cols    = ['Project Cost']\n",
    "\n",
    "#del\n",
    "for i in ['Teacher Project Posted Sequence', 'Project Fully Funded Date', \n",
    "          'Project Expiration Date', 'Project Subject Subcategory Tree', \n",
    "          'Project Posted Date','Project Title','Project Short Description']:\n",
    "    del df[i]\n",
    "del calendar\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Teacher Information\n",
      "Merging School Information\n",
      "Merging Resource Managment\n"
     ]
    }
   ],
   "source": [
    "#Null values from all data sources\n",
    "\n",
    "#plot_empties(bad_form)\n",
    "del plot_empties\n",
    "\n",
    "#Teachers\n",
    "print('Merging Teacher Information')\n",
    "\n",
    "#Treating Nulls in 'Teachers'\n",
    "bad_form['Teachers']['Teacher Prefix'] = bad_form['Teachers']['Teacher Prefix'].apply(\n",
    "    lambda x: 'Teacher' if x in ['Mx.', np.nan] else x)\n",
    "\n",
    "#merging teacher to df\n",
    "df = df.merge(bad_form['Teachers'],on='Teacher ID').copy(deep=True)\n",
    "\n",
    "#cols\n",
    "encode_cols += ['Teacher Prefix']\n",
    "num_cols    += []\n",
    "\n",
    "#del\n",
    "for i in ['Teacher ID','Teacher First Project Posted Date']:\n",
    "    del df[i]\n",
    "#del bad_form['Teachers']\n",
    "gc.collect()\n",
    "\n",
    "#School\n",
    "print('Merging School Information')\n",
    "\n",
    "#very few, dropping nulls\n",
    "bad_form['Schools'] = bad_form['Schools'].dropna()\n",
    "\n",
    "#merging school to df\n",
    "df = df.merge(bad_form['Schools'],on='School ID')\n",
    "df['School Zip'] = df['School Zip'].astype(str)\n",
    "\n",
    "#cols\n",
    "encode_cols += ['School Metro Type','School State','School District','School Zip']\n",
    "num_cols    += ['School Percentage Free Lunch']\n",
    "\n",
    "#del\n",
    "for i in ['School Name','School ID','School City','School County']:\n",
    "    del df[i]\n",
    "#del bad_form['Schools']\n",
    "gc.collect()\n",
    "\n",
    "# Resource Management\n",
    "print('Merging Resource Managment')\n",
    "\n",
    "#more funding features\n",
    "bad_form['Resources']['Resource Total Cost'] = bad_form['Resources']['Resource Quantity'] * bad_form['Resources']['Resource Unit Price']\n",
    "funding_agg = bad_form['Resources'].groupby('Project ID').agg(\n",
    "    {'Resource Item Name': ['nunique'], \n",
    "     'Resource Quantity': ['sum'], \n",
    "     'Resource Total Cost': ['mean', 'sum','median','max','min']})\n",
    "\n",
    "funding_agg.columns = ['Project num Unique Resources',\n",
    "                   'Total Resource Quantity', \n",
    "                   'Mean Resource Cost', \n",
    "                   'Total Project Cost',\n",
    "                   'Median Resource Cost',\n",
    "                   'Most exp Resource Cost',\n",
    "                   'Least exp Resource Cost']\n",
    "\n",
    "#cols\n",
    "encode_cols += []\n",
    "num_cols    += list(funding_agg.columns.values)\n",
    "\n",
    "#merging funding to df\n",
    "funding_agg.reset_index(inplace=True)\n",
    "df = df.merge(funding_agg,on='Project ID')\n",
    "\n",
    "del funding_agg, df['Project ID'], \n",
    "#del bad_form['Resources']\n",
    "gc.collect()\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#s = set(encode_cols+num_cols)\n",
    "#df[[x for x in df.columns if x not in s]].head(5)\n",
    "\n",
    "\n",
    "\n",
    "#compressing data\n",
    "print('Compressing Data')\n",
    "compress(df,encode_cols,num_cols)\n",
    "\n",
    "del compress\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing Data\n",
      "Data Usage - change:Index                              0\n",
      "Project Cost                   -5790\n",
      "School Percentage Free Lunch   -5790\n",
      "Project num Unique Resources   -5790\n",
      "Total Resource Quantity        -5790\n",
      "Mean Resource Cost             -5790\n",
      "Total Project Cost             -5790\n",
      "Median Resource Cost           -5790\n",
      "Most exp Resource Cost         -5790\n",
      "Least exp Resource Cost        -5790\n",
      "Project Type                       0\n",
      "Project Posted Year                0\n",
      "Project Posted Month               0\n",
      "Project Grade Level Category       0\n",
      "Project Resource Category          0\n",
      "Teacher Prefix                     0\n",
      "School Metro Type                  0\n",
      "School State                       0\n",
      "School District                    0\n",
      "School Zip                         0\n",
      "dtype: int64\n",
      "Total Change: -52110\n",
      "Preprocessing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Encoding / Scaling\n",
    "\n",
    "#Preprocessing\n",
    "print('Preprocessing')\n",
    "\n",
    "#Encoding\n",
    "if One_Hot:\n",
    "    df = df.merge(pd.get_dummies(df[encode_cols])\n",
    "             ,left_index=True,right_index=True)\n",
    "    for i in encode_cols:\n",
    "        del df[i]\n",
    "else:\n",
    "    for c in tqdm_notebook(encode_cols):\n",
    "        encod = LabelEncoder()\n",
    "        encod.fit(df[c].astype(str))\n",
    "        df[c] = encod.transform(df[c].astype(str))\n",
    "    del encod\n",
    "\n",
    "p = cat_cleaner(df,'Project Subject Category Tree')\n",
    "df = df.merge(p,left_index=True,right_index=True)\n",
    "del df['Project Subject Category Tree'], p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6865"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling\n",
    "if Standard_Scale:\n",
    "    Scalar = StandardScaler()\n",
    "else:\n",
    "    Scalar = MinMaxScaler()\n",
    "\n",
    "df[num_cols] = Scalar.fit_transform(df[num_cols])\n",
    "\n",
    "del One_Hot, LabelEncoder, Standard_Scale, Scalar\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Processing\n"
     ]
    }
   ],
   "source": [
    "### Text Editing\n",
    "\n",
    "print('Text Processing')\n",
    "\n",
    "text_cols = ['Project Essay','Project Need Statement']\n",
    "\n",
    "#adding more words to 'stopwords'\n",
    "extra_words = ['student','students','education']\n",
    "single_l = [x for x in 'abcdefghijklmnopqrstuvwxyz']\n",
    "for j in single_l:\n",
    "    extra_words.append(j)\n",
    "extra_words += stopwords.words(\"english\")\n",
    "\n",
    "for i in text_cols:\n",
    "    df[i] = df[i].apply(lambda x: text_cleaner(x,extra_words))\n",
    "\n",
    "del text_cleaner, extra_words, single_l, stopwords\n",
    "\n",
    "#Tfidf\n",
    "tfidf = TfidfVectorizer(max_features=Tf_Features, ngram_range=(1,N_Gram))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#er  = {}\n",
    "#er[i+'_tf'] = pd.DataFrame(tfidf.transform(df[i]).todense(),columns=tf_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in text_cols:\n",
    "    tfidf.fit(df[i])\n",
    "    tf_cols = [str(i)+' contains: \"'+str(x)+'\"' for x in list(tfidf.vocabulary_.keys())]\n",
    "    df = df.merge(pd.DataFrame(tfidf.transform(df[i]).todense(),columns=tf_cols), left_index=True, right_index=True)\n",
    "\n",
    "for i in text_cols:\n",
    "    del df[i]\n",
    "del tfidf, tf_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Project Current Status'],axis=1)\n",
    "y = df['Project Current Status']\n",
    "df_cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Project Cost', 'School Percentage Free Lunch',\n",
       "       'Project num Unique Resources', 'Total Resource Quantity',\n",
       "       'Mean Resource Cost', 'Total Project Cost', 'Median Resource Cost',\n",
       "       'Most exp Resource Cost', 'Least exp Resource Cost', 'Applied Learning',\n",
       "       ...\n",
       "       'Project Need Statement contains: \"printer\"',\n",
       "       'Project Need Statement contains: \"access\"',\n",
       "       'Project Need Statement contains: \"literature\"',\n",
       "       'Project Need Statement contains: \"digital\"',\n",
       "       'Project Need Statement contains: \"apple\"',\n",
       "       'Project Need Statement contains: \"well\"',\n",
       "       'Project Need Statement contains: \"like\"',\n",
       "       'Project Need Statement contains: \"life\"',\n",
       "       'Project Need Statement contains: \"kits\"',\n",
       "       'Project Need Statement contains: \"notebooks\"'],\n",
       "      dtype='object', length=216)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
